PRELIMINARY DATA ANALYSIS
gunzip  Nlemb1.fastq.gz, Nlemb3.fastq.gz, NL1.fastq.gz, LinL1.fastq.gz. (Unzip all raw reads)
gunzip Linlemb1.fastq.gz, Linlemb2.fastq.gz, NL2.fastq.gz, LinL2.fastq.gz (Unzip all raw reads)
gunzip  Nlemb2.fastq.gz, Linlemb3.fastq.gz,  NL3.fastq.gz,  LinL3.fastq.gz (Unzip all raw reads)
fastqc Nlemb1.fastq, Nlemb3.fastq, NL1.fastq, LinL1.fastq. (To quality assess raw reads)
fastqc Linlemb1.fastq, Linlemb2.fastq, NL2.fastq, LinL2.fastq. (To quality assess raw reads)
fastqc Nlemb2.fastq, Linlemb3.fastq,  NL3.fastq,  LinL3.fastq. (To quality assess raw reads)
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_rna.fna.gz (to download C. elegans reference transcript)
GCF_000002985.6_WBcel235_rna.fna.gz is the Reference transcript
gunzip GCF_000002985.6_WBcel235_rna.fna.gz> Ref_transcript_rna.fna (to unzip the transcript, output file is GCF_000002985.6_WBcel235_rna.fna)
conda activate RNASeq
bowtie2-build Ref_transcript_rna.fna Ref.elegans (Ref_transcript_rna.fna)
bowtie2 -x Ref.elegans Nlemb1.fastq, Nlemb3.fastq, NL1.fastq, LinL1.fastq. -S Nlemb1.sam, Nlemb3.sam, NL1.sam, LinL1.sam. (to map the indexed transcript into raw RNA reads)
bowtie2 -x Ref.elegans Linlemb1.fastq, Linlemb2.fastq, NL2.fastq, LinL2.fastq. -S Linlemb1.sam, Linlemb2.sam, NL2.sam, LinL2.sam. (to map the indexed transcript into raw RNA reads)
bowtie2 -x Ref.elegans Nlemb2.fastq, Linlemb3.fastq,  NL3.fastq,  LinL3.fastq. -S Nlemb2.sam, Linlemb3.sam,  NL3.sam,  LinL3.sam.
(grep -c "K0" *.sam (count the number of mapped reads in all .sam files to the reference transcriptome)
samtools view -b Nlemb1.sam, Nlemb3.sam, NL1.sam, LinL1.sam | samtools sort - > Nlemb1.bam, Nlemb3.bam, NL1.bam, LinL1.bam (To convert sam to .bam file using samtools)
samtools view -b Linlemb1.sam, Linlemb2.sam, NL2.sam, LinL2.sam | samtools sort - > Linlemb1.bam, Linlemb2.bam, NL2.bam, LinL2.bam
samtools view -b Nlemb2.sam, Linlemb3.sam,  NL3.sam,  LinL3.sam. | samtools sort - > Nlemb2.bam, Linlemb3.bam,  NL3.bam,  LinL3.bam.
samtools index Nlemb1.bam, Nlemb3.bam, NL1.bam, LinL1.bam (Index the .bam file)
samtools index Linlemb1.bam, Linlemb2.bam, NL2.bam, LinL2.bam
samtools index Nlemb2.bam, Linlemb3.bam,  NL3.bam,  LinL3.bam.
bcftools mpileup -f Ref_transcript_rna.fna Nlemb1.bam, Nlemb3.bam, NL1.bam, LinL1.bam | bcftools call -mv -Ob --ploidy 1 -o Nlemb1.rawcalls.bcf, Nlemb3.rawcalls.bcf, NL1.rawcalls.bcf, LinL1.rawcalls.bcf
bcftools mpileup -f Ref_transcript_rna.fna Linlemb1.bam, Linlemb2.bam, NL2.bam, LinL2.bam | bcftools call -mv -Ob --ploidy 1 -o Linlemb1.rawcalls.bcf, Linlemb2.rawcalls.bcf, NL2.rawcalls.bcf, LinL2.rawcalls.bcf
bcftools mpileup -f Ref_transcript_rna.fna Nlemb1.bam, Nlemb3.bam, NL1.bam, LinL1.bam | bcftools call -mv -Ob --ploidy 1 -o Nlemb2.rawcalls.bcf, Linlemb3.rawcalls.bcf,  NL3.rawcalls.bcf,  LinL3.rawcalls.bcf
bcftools filter --exclud 'QUAL < 30' Nlemb1.rawcalls.bcf, Nlemb3.rawcalls.bcf, NL1.rawcalls.bcf, LinL1.rawcalls.bcf > Nlemb1.vcf, Nlemb3.vcf, NL1.vcf, LinL1.vcf (to filter the variant calls)
bcftools filter --exclud 'QUAL < 30' Linlemb1.rawcalls.bcf, Linlemb2.rawcalls.bcf, NL2.rawcalls.bcf, LinL2.rawcalls.bcf > Linlemb1.vcf, Linlemb2.vcf, NL2.vcf, LinL2.vcf
bcftools filter --exclud 'QUAL < 30' Nlemb2.rawcalls.bcf, Linlemb3.rawcalls.bcf,  NL3.rawcalls.bcf,  LinL3.rawcalls.bcf > Nlemb2.vcf, Linlemb3.vcf,  NL3.vcf,  LinL3.vcf
grep -c "NR" Nlemb1.vcf, Nlemb3.vcf, NL1.vcf, LinL1.vcf (to count the number of variant calls in the mapped read). 
grep -c "NR" Linlemb1.vcf, Linlemb2.vcf, NL2.vcf, LinL2.vcf
grep -c "NR" Nlemb2.vcf, Linlemb3.vcf,  NL3.vcf,  LinL3.vcf


DIFFERENTIAL EXPRESSION (Using Salmon)
conda config --add channels conda-forge
conda config --add channels bioconda
conda create -n salmon salmon (to get started with Salmon)
conda activate salmon (To activate salmon)
salmon -h (to read if salmon is active)
salmon index -t GCF_000002985.6_WBcel235_rna.fna -i Reference_index (To index reference transcriptome with Salmon)
salmon quant -i Reference_index -l A -r Nlemb1.fastq.gz -o Nlemb1_transcripts_quant (To obtain a counts table using Salmon command "quant")
salmon quant -i Reference_index -l A -r Nlemb3.fastq.gz -o Nlemb3_transcripts_quant
salmon quant -i Reference_index -l A -r NL1.fastq.gz -o NL1_transcripts_quant
salmon quant -i Reference_index -l A -r LinL1.fastq.gz -o LinL1_transcripts_quant
salmon quant -i Reference_index -l A -r Linlemb1.fastq.gz -o Linlemb1_transcripts_quant
salmon quant -i Reference_index -l A -r Linlemb2.fastq.gz -o Linlemb2_transcripts_quant
salmon quant -i Reference_index -l A -r NL2.fastq.gz -o NL2_transcripts_quant
salmon quant -i Reference_index -l A -r LinL2.fastq.gz -o LinL2_transcripts_quant
salmon quant -i Reference_index -l A -r Nlemb2.fastq.gz -o Nlemb2_transcripts_quant
salmon quant -i Reference_index -l A -r Linlemb3.fastq.gz -o Linlemb3_transcripts_quant
salmon quant -i Reference_index -l A -r NL3.fastq.gz -o NL3_transcripts_quant
salmon quant -i Reference_index -l A -r LinL3.fastq.gz -o LinL3_transcripts_quant

DIFFERENTIAL GENE EXPRESSION analyses on R
library(readr)
library(tidyverse)
library(DESeq2)
(To transfer data sets into R)
read_tsv("Counts/LinL1.sf")
LinL1<- read_tsv("Counts/LinL1.sf")
LinL2<- read_tsv("Counts/LinL2.sf")
LinL3<- read_tsv("Counts/LinL3.sf")
Linlemb1<- read_tsv("Counts/Linlemb1.sf")
Linlemb2<- read_tsv("Counts/Linlemb2.sf")
Linlemb3<- read_tsv("Counts/Linlemb3.sf")
NL1<- read_tsv("Counts/NL1.sf")
NL2<- read_tsv("Counts/NL2.sf")
NL3<- read_tsv("Counts/NL3.sf")
Nlemb1<- read_tsv("Counts/Nlemb1.sf")
Nlemb2<- read_tsv("Counts/Nlemb2.sf")
Nlemb3<- read_tsv("Counts/Nlemb3.sf")
(To filter data sets)
O.LinL1<- LinL1%>%
  select(c("Name", "NumReads"))
O.LinL2<- LinL2%>%
  select(c("Name", "NumReads"))
O.LinL3<- LinL3%>%
  select(c("Name", "NumReads"))
O.Linlemb1<- Linlemb1%>%
  select(c("Name", "NumReads"))
O.Linlemb2<- Linlemb2%>%
  select(c("Name", "NumReads"))
O.Linlemb3<- Linlemb3%>%
  select(c("Name", "NumReads"))
O.NL1<- NL1%>%
  select(c("Name", "NumReads"))
O.NL2<- NL2%>%
  select(c("Name", "NumReads"))
O.NL3<- NL3%>%
  select(c("Name", "NumReads"))
O.Nlemb1<- Nlemb1%>%
  select(c("Name", "NumReads"))
O.Nlemb2<- Nlemb2%>%
  select(c("Name", "NumReads"))
O.Nlemb3<- Nlemb3%>%
  select(c("Name", "NumReads"))
(To change column name to each treatment id)
colnames(O.LinL1)<-c("Gene ID", "LinL1")
colnames(O.LinL2)<-c("Gene ID", "LinL2")
colnames(O.LinL3)<-c("Gene ID", "LinL3")
colnames(O.Linlemb1)<-c("Gene ID", "Linlemb1")
colnames(O.Linlemb2)<-c("Gene ID", "Linlemb2")
colnames(O.Linlemb3)<-c("Gene ID", "Linlemb3")
colnames(O.NL1)<-c("Gene ID", "NL1")
colnames(O.NL2)<-c("Gene ID", "NL2")
colnames(O.NL3)<-c("Gene ID", "NL3")
colnames(O.Nlemb1)<-c("Gene ID", "Nlemb1")
colnames(O.Nlemb2)<-c("Gene ID", "Nlemb2")
colnames(O.Nlemb3)<-c("Gene ID", "Nlemb3")
(To merge data files from each replicates)
merged.Nemb<- O.Nlemb1%>%
  full_join(O.Nlemb2)%>%
  full_join(O.Nlemb3)
merged.NL<- O.NL1%>%
  full_join(O.NL2)%>%
  full_join(O.NL3)
merged.Linemb<- O.Linlemb1%>%
  full_join(O.Linlemb2)%>%
  full_join(O.Linlemb3)
merged.LinL<- O.LinL1%>%
  full_join(O.LinL2)%>%
  full_join(O.LinL3)
(To put files in data frame format)
merged.Nemb <- as.data.frame(merged.Nemb)
merged.NL <- as.data.frame(merged.NL)
merged.Linemb <- as.data.frame(merged.Linemb)
merged.LinL <- as.data.frame(merged.LinL)

(To further organize the files with mean values of each rows)
merged.Nemb[c("Nlemb.X")] <- NA
M.Nemb<-mutate(merged.Nemb, Nlemb.X=(Nlemb1+Nlemb2+Nlemb3)/3)
merged.Linemb[c("Linlemb.X")] <- NA
M.Linemb<-mutate(merged.Linemb, Linlemb.X=(Linlemb1+Linlemb2+Linlemb3)/3)
merged.NL[c("NL")] <- NA
M.NL<-mutate(merged.NL, NL.X=(NL1+NL2+NL3)/3)
merged.LinL[c("LinL.X")] <- NA
M.LinL<-mutate(merged.LinL, LinL.X=(LinL1+LinL2+LinL3)/3)
merged.LinL <-merged.LinL %>% mutate_at(vars(LinL1, LinL2, LinL3), funs(round(., 0)))
merged.Linemb <-merged.Linemb %>% mutate_at(vars(Linlemb1,Linlemb2, Linlemb3), funs(round(., 0)))
merged.NL <-merged.NL %>% mutate_at(vars(NL1, NL2, NL3), funs(round(., 0)))
merged.Nemb <-merged.Nemb %>% mutate_at(vars(Nlemb1, Nlemb2, Nlemb3), funs(round(., 0)))
(To organize data into the different cases that exist; cases represent my hypothesis testing models so I just bin the organized data into categories)
Case.1<- merged.LinL%>%
  full_join(merged.NL)
Case.2<- merged.Linemb%>%
  full_join(merged.Nemb)
Case.3<- merged.Nemb%>%
  full_join(merged.NL)
Case.4<- merged.Linemb%>%
  full_join(merged.LinL)
total.case<- merged.NL%>%
  full_join(merged.LinL)%>%
  full_join(merged.Linemb)%>%
  full_join(merged.Nemb)
(To delete unwanted colunms in each case files)
Case.1 <-select (Case.1,-c(LinL.X,NL))
Case.2 <-select (Case.2,-c(Linlemb.X,Nlemb.X))
Case.3 <-select (Case.3,-c(Nlemb.X,NL))
Case.4 <-select (Case.4,-c(Linlemb.X,LinL.X))
total.case <-select (total.case,-c(Linlemb.X,LinL.X,Nlemb.X,NL))
(My data values in each case files were in 2.decimal places so I need to round them all off to whole numbers, to do this I used the pipelines below)
Case.1 <-Case.1 %>% mutate_at(vars(LinL1, LinL2, LinL3, NL1, NL2, NL3), funs(round(., 0)))
Case.2 <-Case.2 %>% mutate_at(vars(Linlemb1,Linlemb2, Linlemb3, Nlemb1, Nlemb2, Nlemb3), funs(round(., 0)))
Case.3 <-Case.3 %>% mutate_at(vars(Nlemb1, Nlemb2, Nlemb3, NL1, NL2, NL3), funs(round(., 0)))
Case.4 <-Case.4 %>% mutate_at(vars(LinL1, LinL2, LinL3, Linlemb1, Linlemb2, Linlemb3), funs(round(., 0)))
total.case <-total.case %>% mutate_at(vars(LinL1, LinL2, LinL3, Linlemb1, Linlemb2, Linlemb3, Nlemb1, Nlemb2, Nlemb3, NL1, NL2, NL3), funs(round(., 0)))
(To input the metadata files, case files as well as total case have a metadata file each)
read_csv("Counts/metadata.csv")
choice_metadata<- read_csv("Counts/metadata.csv")
choice_metadata<- as.data.frame (choice_metadata)
read_csv("Counts/metadata.csv")
choice_metadata<- read_csv("Counts/choicemetadata.csv")
choice_metadata<- as.data.frame (choice_metadata)
metadata1<- read_csv("Counts/metadata1.csv")
metadata1<- as.data.frame (metadata1)
metadata2<- read_csv("Counts/metadata2.csv")
metadata2<- as.data.frame (metadata2
metadata3<- read_csv("Counts/metadata3.csv")
metadata3<- as.data.frame (metadata3)
metadata4<- read_csv("Counts/metadata4.csv")
metadata4<- as.data.frame (metadata4)
(To create a DESeq object for the case files)
total.case_dds <- DESeqDataSetFromMatrix(countData= total.case, 
                                    colData=choice_metadata, 
                                    design=~dex, 
                                    tidy=TRUE)
out1 <- DESeqDataSetFromMatrix(countData= Case.1, 
                                         colData=metadata1, 
                                         design=~dex, 
                                         tidy=TRUE)
out2 <- DESeqDataSetFromMatrix(countData= Case.2, 
                                     colData=metadata2, 
                                     design=~dex, 
                                     tidy=TRUE)
out3 <- DESeqDataSetFromMatrix(countData= Case.3, 
                                     colData=metadata3, 
                                     design=~dex, 
                                     tidy=TRUE)
out4 <- DESeqDataSetFromMatrix(countData= Case.4, 
                                     colData=metadata4, 
                                     design=~dex, 
                                     tidy=TRUE)
(To run DESeq2 on the DESeq objects)
tcase <- DESeq(total.case_dds)
out.case1 <- DESeq(out1)
out.case2 <- DESeq(out2)
out.case3 <- DESeq(out3)
out.case4 <- DESeq(out4)
(To organize my results into tables)
totalres <- results(tcase, tidy=TRUE)
o.res1 <- results(out.case1, tidy=TRUE)
o.res2 <- results(out.case2, tidy=TRUE)
o.res3 <- results(out.case3, tidy=TRUE)
o.res4 <- results(out.case4, tidy=TRUE)
(To manipulate my table results and filter out what is needed)
totalres <- tbl_df(totalres)
o.res1 <- tbl_df(o.res1)
o.res2 <- tbl_df(o.res2)
o.res3 <- tbl_df(o.res3)
o.res4 <- tbl_df(o.res4)
tres <- arrange(totalres, padj)
resA <- arrange(o.res1, padj)
resB <- arrange(o.res2, padj)
resC <- arrange(o.res3, padj)
resD <- arrange(o.res4, padj)
(To sort out data files such that significance and fold change functions are included)
tres.filtered <- arrange(tres, padj)
tres.upregulated <- filter(tres.filtered, padj<=0.05 & log2FoldChange>=2.0)
tres.downreg <- filter(tres.filtered, padj<=0.05 & log2FoldChange<=-2.0)
tres.mutated <-mutate(tres.filtered,significance=ifelse(padj<0.05,"Significant","Non-significant"))
tres.upreg<-mutate(tres.upregulated,significance=ifelse(padj<0.05,"Significant","Non-significant"))
tres.down<-mutate(tres.downreg,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case1.filtered <- arrange(resA, padj)
case1.mutated <-mutate(case1.filtered,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case1.upregulated <- filter(case1.filtered, padj<=0.05 & log2FoldChange>=2.0)
case1.downreg <- filter(case1.filtered, padj<=0.05 & log2FoldChange<=-2.0)
case1.upreg<-mutate(case1.upregulated,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case1.down<-mutate(case1.downreg,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case2.filtered <- arrange(resB, padj)
case2.mutated <-mutate(case2.filtered,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case2.upregulated <- filter(case2.filtered, padj<=0.05 & log2FoldChange>=2.0)
case2.downreg <- filter(case2.filtered, padj<=0.05 & log2FoldChange<=-2.0)
case2.upreg<-mutate(case2.upregulated,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case2.down<-mutate(case2.downreg,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case3.filtered <- arrange(resC, padj)
case3.mutated <-mutate(case3.filtered,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case3.upregulated <- filter(case3.filtered, padj<=0.05 & log2FoldChange>=2.0)
case3.downreg <- filter(case3.filtered, padj<=0.05 & log2FoldChange<=-2.0)
case3.upreg<-mutate(case3.upregulated,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case3.down<-mutate(case3.downreg,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case4.filtered <- arrange(resD, padj)
case4.mutated <-mutate(case4.filtered,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case4.upregulated <- filter(case4.filtered, padj<=0.05 & log2FoldChange>=2.0)
case4.downreg <- filter(case4.filtered, padj<=0.05 & log2FoldChange<=-2.0)
case4.upreg<-mutate(case4.upregulated,significance=ifelse(padj<0.05,"Significant","Non-significant"))
case4.down<-mutate(case4.downreg,significance=ifelse(padj<0.05,"Significant","Non-significant"))

(To create a monovariant file for Venn diagrams and ellipses)
Ven1a<- filter(case1.mutated, treatment== "control")
Ven1b<- filter(case1.mutated, treatment== "mutant")
Ven2a<- filter(case2.mutated, treatment== "control")
Ven2b<- filter(case2.mutated, treatment== "mutant")
Ven3a<- filter(case3.mutated, treatment== "control")
Ven3b<- filter(case3.mutated, treatment== "mutant")
Ven4a<- filter(case4.mutated, treatment== "control")
install.packages("VennDiagram")
library(VennDiagram)
(To plot Venn diagrams for gene expression levels) 


